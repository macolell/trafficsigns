{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision, torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as f\n",
    "import torch.optim as optim \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage import io\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      file_name  width  height  x1  y1   x2   y2  category\n",
      "0  000_0001.png    134     128  19   7  120  117         0\n"
     ]
    }
   ],
   "source": [
    "import imageio\n",
    "from skimage.transform import resize\n",
    "list = pd.read_csv('/Users/michaelcolellajensen/Desktop/Data Sets/annotations.csv')\n",
    "file_name = list['file_name'].values\n",
    "print(list.head(1))\n",
    "for image in file_name:\n",
    "    #read image\n",
    "    img_io = imageio.imread('/Users/michaelcolellajensen/Downloads/archive/images/{}'.format(image))\n",
    "\n",
    "    #Resize image\n",
    "    img_io = resize(img_io, (26, 26))\n",
    "\n",
    "    # Write ICO image\n",
    "    imageio.imwrite('/Users/michaelcolellajensen/Desktop/images/{}'.format(image), img_io)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build a new calss object for the images \n",
    "class TrafficSigns(Dataset):\n",
    "    #constructure will need csv file of labels images and the transform function defined above\n",
    "    def __init__(self, \n",
    "                 csv_file, \n",
    "                 root_directory, \n",
    "                 transform = None):\n",
    "        self.labels = pd.read_csv(csv_file)\n",
    "        self.root_directory = root_directory\n",
    "        self.transform = transform\n",
    "    #returns the length \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    #get data index by indes\n",
    "    def __getitem__(self, i):\n",
    "        image_path = os.path.join(self.root_directory, self.labels.iloc[i,0])\n",
    "        image = io.imread(image_path)\n",
    "        y_label = torch.tensor(int(self.labels.iloc[i, 1]))\n",
    "        \n",
    "        #if statement needed since transform can be set to None \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return (image, y_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperprams\n",
    "learning_rate = 5e-4\n",
    "#3 for RGB values \n",
    "in_channel = 3\n",
    "#classes from data set \n",
    "num_classes = 57\n",
    "# arbitray choice \n",
    "batch_size = 24\n",
    "#total number of epochs used to train the model \n",
    "epochs = 3\n",
    "\n",
    "traffic_dataset = TrafficSigns('/Users/michaelcolellajensen/Desktop/Data Sets/annotations.csv',\n",
    "                       '/Users/michaelcolellajensen/Desktop/images',\n",
    "                       transform = transforms.ToTensor())\n",
    "train_size = int(0.8 * len(traffic_dataset))\n",
    "test_size = len(traffic_dataset) - train_size\n",
    "train, test = torch.utils.data.random_split(traffic_dataset,\n",
    "                                            [train_size, test_size])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train,\n",
    "                                           batch_size= batch_size, \n",
    "                                           shuffle= True, \n",
    "                                           num_workers= 6)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test, \n",
    "                                          batch_size = batch_size, \n",
    "                                          shuffle= True, \n",
    "                                          num_workers= 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a fully connected nn\n",
    "class Net(nn.Module):\n",
    "    #use the constructor w/ arguements size of data and number of classes\n",
    "    def __init__(self, \n",
    "                 input_size, \n",
    "                 num_classes):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 50)\n",
    "        self.fc2 = nn.Linear(50, num_classes)\n",
    "    #define your forward step function with relu as the non-linear function of the weights\n",
    "    #x will be the datapassed to the model \n",
    "    def forward(self, x):\n",
    "        x=f.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'TrafficSigns' on <module '__main__' (built-in)>\n"
     ]
    }
   ],
   "source": [
    "#instantiate the class object of NN\n",
    "net = Net(2028, 57)\n",
    "learning_rate = 5e-4\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "nn_optimizer = optim.Adam(net.parameters(), \n",
    "                          lr = learning_rate)\n",
    "\n",
    "#train on multiple epochs using the criterion and gradient decent algorthim estabilished above\n",
    "for epoch in range(1):\n",
    "    for i, (data,target) in enumerate(train_loader):\n",
    "     data = data.reshape(data.shape[0], -1)\n",
    "     nn_optimizer.zero_grad()\n",
    "     #forward\n",
    "     outputs = net(data)\n",
    "     loss = criterion(outputs, target)\n",
    "     #backward propigation\n",
    "     nn_optimizer.zero_grad()\n",
    "     loss.backward()\n",
    "     nn_optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate model performance on the test data\n",
    "#create variables to count correct predictins and total predictions\n",
    "nn_correct, nn_total = 0, 0\n",
    "#empty list to hold the predicted probabilities of each class \n",
    "nn_predictions = []\n",
    "#model must be put in eval mode before testing \n",
    "net.eval()\n",
    "for i, data in enumerate(test, 0):\n",
    "    inputs, labels = data\n",
    "    inputs = inputs.view(-1, 15750) \n",
    "    outputs = net(inputs) \n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    nn_predictions.append(outputs)\n",
    "    nn_total += labels.size(0)\n",
    "    nn_correct += (predicted == labels).sum()\n",
    "    nn_percent = format((100*nn_correct/nn_total), '.2f')\n",
    "print('The test accuracy of the model is: {}%'.format(nn_percent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#building a convolutional neural network for images \n",
    "class CNNet(nn.Module):\n",
    "    def __init__(self,num_classes):\n",
    "        super(CNNet, self).__init__()\n",
    "        #using a 3x3 kernal and 1x1 padding/stride the num of inut features will match output features\n",
    "        self.conv1 = nn.Conv2d(in_channels=3,\n",
    "                               out_channels=15,\n",
    "                               kernel_size= (3,3),\n",
    "                               stride=(1,1),\n",
    "                               padding= (1,1),\n",
    "                               bias=True)\n",
    "        #in channels on second layer must match out on first layer \n",
    "        self.conv2 = nn.Conv2d(in_channels= 15,\n",
    "                               out_channels= 30,\n",
    "                               kernel_size=(3,3),\n",
    "                               stride = (1,1),\n",
    "                               padding=(1,1),\n",
    "                               bias=True)\n",
    "        #can use max pooling again but careful to ensure features are still whole numbers \n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        #last level is fully connected with num out channels * original image dem /2 and /2 again\n",
    "        self.fc = nn.Linear(30 * 13 * 13 * 3, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "            x = f.relu(self.conv1(x))\n",
    "            x = f.relu(self.conv2(x))\n",
    "            x = self.pool(x)\n",
    "            x = x.reshape(x.shape[0], -1)\n",
    "            x = self.fc(x)\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate the class object of CNNet\n",
    "cnn = CNNet(57)\n",
    "cnn_optimizer = optim.Adam(cnn.parameters(), lr = learning_rate)\n",
    "#training the CNN \n",
    "\n",
    "for epoch in range(1):\n",
    "    for i, (data,target) in enumerate(train_loader):\n",
    "     cnn_optimizer.zero_grad()\n",
    "     #forward\n",
    "     outputs = cnn(data)\n",
    "     loss = criterion(outputs, target)\n",
    "     #backward propigation\n",
    "     cnn_optimizer.zero_grad()\n",
    "     loss.backward()\n",
    "     cnn_optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate the CNN performace \n",
    "cnn.eval()\n",
    "cnn_correct, cnn_total = 0, 0\n",
    "#empty list to hold the predicted probabilities of each class \n",
    "cnn_predictions = []\n",
    "for i, data in enumerate(test_loader, 0):\n",
    "    inputs, labels = data\n",
    "    outputs = cnn(inputs) \n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    cnn_predictions.append(predicted)\n",
    "    cnn_total += labels.size(0)\n",
    "    cnn_correct += (predicted == labels).sum()\n",
    "    cnn_percent = format((cnn_correct/cnn_total * 100), '.2f')\n",
    "print('The test accuracy of the model is: {}%'.format(cnn_percent))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
